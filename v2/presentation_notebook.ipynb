{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Optimization for FCPM Director Reconstruction\n",
    "## A Comprehensive Comparison of Advanced Methods\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem\n",
    "\n",
    "In nematic liquid crystals, the director **n** has a fundamental symmetry: **n ≡ -n**. After Q-tensor eigendecomposition, each voxel has a director with an **arbitrary sign**. We need to find consistent signs that produce a smooth, physically realistic field.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "**Objective**: Minimize gradient energy\n",
    "$$E(S) = \\sum_{(i,j) \\in \\text{neighbors}} |s_i \\cdot \\hat{n}_i - s_j \\cdot \\hat{n}_j|^2$$\n",
    "\n",
    "where $s_i \\in \\{+1, -1\\}$ for each voxel.\n",
    "\n",
    "**Equivalence to Ising Model**:\n",
    "$$E(S) = \\sum_{(i,j)} J_{ij} \\cdot s_i \\cdot s_j + \\text{const}$$\n",
    "\n",
    "where $J_{ij} = -2(\\hat{n}_i \\cdot \\hat{n}_j)$\n",
    "\n",
    "---\n",
    "\n",
    "### Methods Compared\n",
    "\n",
    "| # | Method | Approach | Complexity |\n",
    "|---|--------|----------|------------|\n",
    "| 1 | V2 Layer+Refine | Greedy layer propagation | O(N) |\n",
    "| 2 | Graph Cuts | Min-cut/max-flow (exact) | O(N log N) |\n",
    "| 3 | Hierarchical | Coarse-to-fine pyramid | O(N) |\n",
    "| 4 | Simulated Annealing | Stochastic optimization | O(iter × N) |\n",
    "| 5 | Belief Propagation | Message passing | O(iter × N) |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:07.581628Z",
     "start_time": "2026-02-03T06:14:07.366610Z"
    }
   },
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Configure matplotlib for nice plots\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "\n",
    "# Add paths\n",
    "sys.path.insert(0, str(Path('.').resolve().parent))\n",
    "sys.path.insert(0, str(Path('.').resolve()))\n",
    "\n",
    "import fcpm\n",
    "from fcpm.core.director import DirectorField\n",
    "from fcpm.reconstruction import reconstruct_via_qtensor\n",
    "\n",
    "# Import all approaches\n",
    "from sign_optimization_v2 import layer_then_refine, compute_gradient_energy\n",
    "from approaches.graph_cuts import GraphCutsOptimizer\n",
    "from approaches.simulated_annealing import SimulatedAnnealingOptimizer, SimulatedAnnealingConfig\n",
    "from approaches.hierarchical import HierarchicalOptimizer\n",
    "from approaches.belief_propagation import BeliefPropagationOptimizer, BeliefPropagationConfig\n",
    "\n",
    "# Check PyMaxflow\n",
    "gc = GraphCutsOptimizer()\n",
    "print(f\"PyMaxflow available: {gc._has_maxflow}\")\n",
    "print(\"All imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMaxflow available: True\n",
      "All imports successful!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Algorithm Descriptions\n",
    "\n",
    "### 1.1 V2 Layer-by-Layer + Refinement\n",
    "\n",
    "**Idea**: Propagate signs layer-by-layer along z-axis, then refine globally.\n",
    "\n",
    "```\n",
    "Phase 1: Layer Propagation\n",
    "──────────────────────────\n",
    "for z = 1 to nz-1:\n",
    "    for each voxel (y,x) in layer z:\n",
    "        if dot(n[y,x,z], n[y,x,z-1]) < 0:\n",
    "            flip n[y,x,z]\n",
    "\n",
    "Phase 2: Iterative Refinement  \n",
    "─────────────────────────────\n",
    "repeat until convergence:\n",
    "    for each voxel:\n",
    "        if flipping reduces energy:\n",
    "            flip\n",
    "```\n",
    "\n",
    "**Pros**: Fast, simple | **Cons**: Gets stuck in local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Graph Cuts (Min-Cut/Max-Flow)\n",
    "\n",
    "**Idea**: Model as binary labeling problem, solve exactly via max-flow.\n",
    "\n",
    "```\n",
    "Step 1: Build Graph\n",
    "───────────────────\n",
    "• Source S = \"positive sign\"\n",
    "• Sink T = \"negative sign\"  \n",
    "• Edge weights from director alignment\n",
    "\n",
    "Step 2: Find Min-Cut\n",
    "────────────────────\n",
    "• Run Boykov-Kolmogorov algorithm\n",
    "• Cut partitions voxels into S-side and T-side\n",
    "\n",
    "Step 3: Assign Signs\n",
    "────────────────────\n",
    "• S-reachable → positive\n",
    "• T-reachable → negative\n",
    "```\n",
    "\n",
    "**Pros**: Globally optimal, fast | **Cons**: Requires library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hierarchical Coarse-to-Fine\n",
    "\n",
    "**Idea**: Solve at coarse scale first, refine progressively.\n",
    "\n",
    "```\n",
    "Step 1: Build Pyramid\n",
    "─────────────────────\n",
    "Level 3: 32×32×16 (original)\n",
    "Level 2: 16×16×8\n",
    "Level 1: 8×8×4  \n",
    "Level 0: 4×4×2 (coarsest)\n",
    "\n",
    "Step 2: Coarsening (2×2×2 blocks)\n",
    "─────────────────────────────────\n",
    "• Average Q-tensors in block\n",
    "• Find dominant eigenvector\n",
    "\n",
    "Step 3: Bottom-Up Refinement\n",
    "────────────────────────────\n",
    "• Solve coarsest level\n",
    "• Upsample signs to finer level\n",
    "• Local refinement\n",
    "• Repeat until original resolution\n",
    "```\n",
    "\n",
    "**Pros**: Fast, captures global structure | **Cons**: May smooth defects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Simulated Annealing\n",
    "\n",
    "**Idea**: Stochastic search with temperature-controlled acceptance.\n",
    "\n",
    "```\n",
    "Initialize: T = T_high\n",
    "\n",
    "repeat:\n",
    "    pick random voxel\n",
    "    compute ΔE if flipped\n",
    "    \n",
    "    if ΔE < 0:\n",
    "        accept flip\n",
    "    else:\n",
    "        accept with probability exp(-ΔE/T)\n",
    "    \n",
    "    T ← α × T  (cooling)\n",
    "    \n",
    "until T < T_min\n",
    "```\n",
    "\n",
    "**Pros**: Can escape local minima | **Cons**: Very slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Belief Propagation\n",
    "\n",
    "**Idea**: Message passing on factor graph for probabilistic inference.\n",
    "\n",
    "```\n",
    "Initialize: all messages = 0.5\n",
    "\n",
    "repeat:\n",
    "    for each edge (u → v):\n",
    "        m_{u→v}(s) = Σ ψ(s_u, s_v) × Π m_{w→u}(s_u)\n",
    "    \n",
    "    apply damping: m ← α×m_old + (1-α)×m_new\n",
    "    \n",
    "until convergence\n",
    "\n",
    "Extract: s* = argmax belief(s)\n",
    "```\n",
    "\n",
    "**Pros**: Parallelizable | **Cons**: May not converge on loopy graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Controlled Test - Scrambled Signs\n",
    "\n",
    "To fairly compare methods, we create a perfect director field and randomly scramble 50% of the signs. This creates a controlled test where we know the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:17.636669Z",
     "start_time": "2026-02-03T06:14:17.613596Z"
    }
   },
   "source": [
    "# Create ground truth cholesteric director\n",
    "SHAPE = (32, 32, 16)\n",
    "PITCH = 6.0\n",
    "\n",
    "print(\"Creating ground truth director...\")\n",
    "director_gt = fcpm.create_cholesteric_director(shape=SHAPE, pitch=PITCH)\n",
    "n_gt = director_gt.to_array()\n",
    "gt_energy = compute_gradient_energy(n_gt)\n",
    "\n",
    "# Scramble signs randomly (50% flip)\n",
    "print(\"Scrambling 50% of signs randomly...\")\n",
    "np.random.seed(42)\n",
    "flip_mask = np.random.random(n_gt.shape[:3]) > 0.5\n",
    "n_scrambled = n_gt.copy()\n",
    "n_scrambled[flip_mask] = -n_scrambled[flip_mask]\n",
    "director_scrambled = DirectorField.from_array(n_scrambled)\n",
    "scrambled_energy = compute_gradient_energy(n_scrambled)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Ground Truth Energy:  {gt_energy:,.0f}\")\n",
    "print(f\"Scrambled Energy:     {scrambled_energy:,.0f}\")\n",
    "print(f\"Energy Gap to Close:  {scrambled_energy - gt_energy:,.0f}\")\n",
    "print(f\"{'='*50}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ground truth director...\n",
      "Scrambling 50% of signs randomly...\n",
      "\n",
      "==================================================\n",
      "Ground Truth Energy:  19,456\n",
      "Scrambled Energy:     98,334\n",
      "Energy Gap to Close:  78,878\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:47.186923Z",
     "start_time": "2026-02-03T06:14:22.275589Z"
    }
   },
   "source": [
    "# Run all methods on scrambled data\n",
    "scrambled_results = {}\n",
    "\n",
    "methods = [\n",
    "    ('V2 Layer+Refine', lambda d: layer_then_refine(d, verbose=False)),\n",
    "    ('Graph Cuts', lambda d: GraphCutsOptimizer().optimize(d, verbose=False)),\n",
    "    ('Hierarchical', lambda d: HierarchicalOptimizer().optimize(d, verbose=False)),\n",
    "    ('Simulated Annealing', lambda d: SimulatedAnnealingOptimizer(\n",
    "        SimulatedAnnealingConfig(max_iterations=50000, use_cluster_moves=True)\n",
    "    ).optimize(d, verbose=False)),\n",
    "    ('Belief Propagation', lambda d: BeliefPropagationOptimizer(\n",
    "        BeliefPropagationConfig(max_iterations=100)\n",
    "    ).optimize(d, verbose=False)),\n",
    "]\n",
    "\n",
    "print(f\"{'Method':<25} {'Final Energy':>14} {'Recovery':>12} {'Time':>10}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for name, method in methods:\n",
    "    t0 = time.time()\n",
    "    result = method(director_scrambled)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    recovery = 100 * (scrambled_energy - result.final_energy) / (scrambled_energy - gt_energy)\n",
    "    \n",
    "    status = \" ★ OPTIMAL\" if abs(result.final_energy - gt_energy) < 1 else \"\"\n",
    "    \n",
    "    scrambled_results[name] = {\n",
    "        'energy': result.final_energy,\n",
    "        'recovery': recovery,\n",
    "        'time': elapsed,\n",
    "        'director': result.director\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:<25} {result.final_energy:>14,.0f} {recovery:>11.1f}% {elapsed:>9.2f}s{status}\")\n",
    "\n",
    "print(\"-\"*65)\n",
    "print(f\"{'Ground Truth':<25} {gt_energy:>14,.0f} {'100.0':>11}% {'N/A':>10}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                      Final Energy     Recovery       Time\n",
      "-----------------------------------------------------------------\n",
      "V2 Layer+Refine                   61,508        46.7%      0.05s\n",
      "Graph Cuts                        19,456       100.0%      0.04s ★ OPTIMAL\n",
      "Hierarchical                      29,696        87.0%      0.04s\n",
      "Simulated Annealing               49,806        61.5%     24.77s\n",
      "Belief Propagation                98,334         0.0%      0.01s\n",
      "-----------------------------------------------------------------\n",
      "Ground Truth                      19,456       100.0%        N/A\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:47.418775Z",
     "start_time": "2026-02-03T06:14:47.192115Z"
    }
   },
   "source": [
    "# Visualization: Energy Recovery Bar Chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "names = list(scrambled_results.keys())\n",
    "recoveries = [scrambled_results[n]['recovery'] for n in names]\n",
    "times = [scrambled_results[n]['time'] for n in names]\n",
    "\n",
    "# Color by performance\n",
    "colors = ['#2ecc71' if r > 95 else '#f39c12' if r > 50 else '#e74c3c' for r in recoveries]\n",
    "\n",
    "# Recovery chart\n",
    "ax = axes[0]\n",
    "bars = ax.bar(range(len(names)), recoveries, color=colors, edgecolor='black', linewidth=1.2)\n",
    "ax.axhline(y=100, color='green', linestyle='--', linewidth=2, label='Optimal (100%)')\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=30, ha='right')\n",
    "ax.set_ylabel('Energy Recovery (%)')\n",
    "ax.set_title('Energy Recovery from Scrambled Signs', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 110)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, recoveries):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "            f'{val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Time chart\n",
    "ax = axes[1]\n",
    "bars = ax.bar(range(len(names)), times, color='steelblue', edgecolor='black', linewidth=1.2)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=30, ha='right')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Computation Time', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, times):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.2, \n",
    "            f'{val:.2f}s', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scrambled_test_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/56t9h5ws6s31gccfg9d7kn9m0000gn/T/ipykernel_21246/584005330.py:43: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Realistic Test - Noisy Reconstruction\n",
    "\n",
    "Now test with realistic FCPM simulation including noise."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:47.442427Z",
     "start_time": "2026-02-03T06:14:47.425901Z"
    }
   },
   "source": [
    "# Realistic reconstruction with noise\n",
    "NOISE_LEVEL = 0.05  # 5% noise\n",
    "\n",
    "print(\"Simulating FCPM measurement...\")\n",
    "I_fcpm = fcpm.simulate_fcpm(director_gt)\n",
    "\n",
    "print(f\"Adding {NOISE_LEVEL*100:.0f}% noise...\")\n",
    "I_noisy = fcpm.add_fcpm_realistic_noise(I_fcpm, noise_model='mixed', gaussian_sigma=NOISE_LEVEL)\n",
    "I_noisy = fcpm.normalize_fcpm(I_noisy)\n",
    "\n",
    "print(\"Reconstructing via Q-tensor...\")\n",
    "director_raw, Q, info = reconstruct_via_qtensor(I_noisy)\n",
    "\n",
    "raw_energy = compute_gradient_energy(director_raw.to_array())\n",
    "raw_metrics = fcpm.summary_metrics(director_raw, director_gt)\n",
    "\n",
    "print(f\"\\nRaw reconstruction (no sign fix):\")\n",
    "print(f\"  Energy: {raw_energy:,.0f}\")\n",
    "print(f\"  Angular error: {raw_metrics['angular_error_mean_deg']:.2f}°\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating FCPM measurement...\n",
      "Adding 5% noise...\n",
      "Reconstructing via Q-tensor...\n",
      "\n",
      "Raw reconstruction (no sign fix):\n",
      "  Energy: 36,872\n",
      "  Angular error: 7.24°\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:59.083586Z",
     "start_time": "2026-02-03T06:14:47.449222Z"
    }
   },
   "source": [
    "# Test methods on noisy reconstruction\n",
    "noisy_results = {}\n",
    "\n",
    "print(f\"{'Method':<25} {'Energy':>12} {'Ang.Error':>12} {'Time':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for name, method in methods:\n",
    "    t0 = time.time()\n",
    "    result = method(director_raw)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    metrics = fcpm.summary_metrics(result.director, director_gt)\n",
    "    \n",
    "    noisy_results[name] = {\n",
    "        'energy': result.final_energy,\n",
    "        'error': metrics['angular_error_mean_deg'],\n",
    "        'time': elapsed,\n",
    "        'director': result.director\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:<25} {result.final_energy:>12,.0f} {metrics['angular_error_mean_deg']:>11.2f}° {elapsed:>9.2f}s\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Raw (no fix)':<25} {raw_energy:>12,.0f} {raw_metrics['angular_error_mean_deg']:>11.2f}° {'N/A':>10}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                          Energy    Ang.Error       Time\n",
      "------------------------------------------------------------\n",
      "V2 Layer+Refine                 20,877        7.24°      0.00s\n",
      "Graph Cuts                      20,877        7.24°      0.04s\n",
      "Hierarchical                    31,221        7.24°      0.05s\n",
      "Simulated Annealing             21,129        7.24°     11.53s\n",
      "Belief Propagation              36,872        7.24°      0.01s\n",
      "------------------------------------------------------------\n",
      "Raw (no fix)                    36,872        7.24°        N/A\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:14:59.467866Z",
     "start_time": "2026-02-03T06:14:59.101827Z"
    }
   },
   "source": [
    "# Director slice visualization\n",
    "z_mid = SHAPE[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Top row\n",
    "fcpm.plot_director_slice(director_gt, z_idx=z_mid, step=2, ax=axes[0, 0], \n",
    "                         title='Ground Truth')\n",
    "fcpm.plot_director_slice(director_scrambled, z_idx=z_mid, step=2, ax=axes[0, 1], \n",
    "                         title='Scrambled Input')\n",
    "fcpm.plot_director_slice(scrambled_results['Graph Cuts']['director'], z_idx=z_mid, step=2, \n",
    "                         ax=axes[0, 2], title='Graph Cuts (100% recovery)')\n",
    "\n",
    "# Bottom row\n",
    "fcpm.plot_director_slice(scrambled_results['V2 Layer+Refine']['director'], z_idx=z_mid, step=2, \n",
    "                         ax=axes[1, 0], title=f\"V2 Layer+Refine ({scrambled_results['V2 Layer+Refine']['recovery']:.0f}%)\")\n",
    "fcpm.plot_director_slice(scrambled_results['Hierarchical']['director'], z_idx=z_mid, step=2, \n",
    "                         ax=axes[1, 1], title=f\"Hierarchical ({scrambled_results['Hierarchical']['recovery']:.0f}%)\")\n",
    "fcpm.plot_director_slice(scrambled_results['Simulated Annealing']['director'], z_idx=z_mid, step=2, \n",
    "                         ax=axes[1, 2], title=f\"Simulated Annealing ({scrambled_results['Simulated Annealing']['recovery']:.0f}%)\")\n",
    "\n",
    "plt.suptitle(f'Director Field Comparison at z={z_mid}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('director_slices_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/56t9h5ws6s31gccfg9d7kn9m0000gn/T/ipykernel_21246/3889862284.py:25: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Noise Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:15:00.011546Z",
     "start_time": "2026-02-03T06:14:59.474610Z"
    }
   },
   "source": [
    "# Quick noise sensitivity test\n",
    "noise_levels = [0.01, 0.03, 0.05, 0.08, 0.10]\n",
    "\n",
    "# Only test fast methods for presentation\n",
    "fast_methods = [\n",
    "    ('V2 Layer+Refine', lambda d: layer_then_refine(d, verbose=False)),\n",
    "    ('Graph Cuts', lambda d: GraphCutsOptimizer().optimize(d, verbose=False)),\n",
    "    ('Hierarchical', lambda d: HierarchicalOptimizer().optimize(d, verbose=False)),\n",
    "]\n",
    "\n",
    "noise_data = {name: {'errors': [], 'energies': []} for name, _ in fast_methods}\n",
    "\n",
    "print(\"Running noise sensitivity analysis...\\n\")\n",
    "\n",
    "for noise in noise_levels:\n",
    "    print(f\"Noise {noise*100:.0f}%: \", end=\"\")\n",
    "    \n",
    "    I_noisy = fcpm.add_fcpm_realistic_noise(I_fcpm, noise_model='mixed', gaussian_sigma=noise)\n",
    "    I_noisy = fcpm.normalize_fcpm(I_noisy)\n",
    "    director_raw_n, _, _ = reconstruct_via_qtensor(I_noisy)\n",
    "    \n",
    "    for name, method in fast_methods:\n",
    "        result = method(director_raw_n)\n",
    "        metrics = fcpm.summary_metrics(result.director, director_gt)\n",
    "        noise_data[name]['errors'].append(metrics['angular_error_mean_deg'])\n",
    "        noise_data[name]['energies'].append(result.final_energy)\n",
    "    \n",
    "    print(f\"done\")\n",
    "\n",
    "print(\"\\nComplete!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running noise sensitivity analysis...\n",
      "\n",
      "Noise 1%: done\n",
      "Noise 3%: done\n",
      "Noise 5%: done\n",
      "Noise 8%: done\n",
      "Noise 10%: done\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:15:00.077367Z",
     "start_time": "2026-02-03T06:15:00.015014Z"
    }
   },
   "source": [
    "# Plot noise sensitivity\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = {'V2 Layer+Refine': '#3498db', 'Graph Cuts': '#2ecc71', 'Hierarchical': '#9b59b6'}\n",
    "markers = {'V2 Layer+Refine': 'o', 'Graph Cuts': 's', 'Hierarchical': '^'}\n",
    "\n",
    "noise_pct = [n * 100 for n in noise_levels]\n",
    "\n",
    "for name in noise_data:\n",
    "    ax.plot(noise_pct, noise_data[name]['errors'], \n",
    "            marker=markers[name], color=colors[name],\n",
    "            linewidth=2.5, markersize=10, label=name)\n",
    "\n",
    "ax.set_xlabel('Noise Level (%)', fontsize=12)\n",
    "ax.set_ylabel('Mean Angular Error (°)', fontsize=12)\n",
    "ax.set_title('Angular Error vs Noise Level', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('noise_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/56t9h5ws6s31gccfg9d7kn9m0000gn/T/ipykernel_21246/1433107349.py:23: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Summary & Conclusions\n",
    "\n",
    "### Performance Ranking\n",
    "\n",
    "| Rank | Method | Energy Recovery | Speed | Recommendation |\n",
    "|------|--------|-----------------|-------|----------------|\n",
    "| **1** | **Graph Cuts** | **100%** (Optimal) | Fast (0.04s) | **Best choice** |\n",
    "| 2 | Hierarchical | 87% | Fast (0.04s) | Good alternative |\n",
    "| 3 | V2 Layer+Refine | 47% | Very Fast (0.03s) | Quick baseline |\n",
    "| 4 | Simulated Annealing | 30-62% | Very Slow (28s) | Not recommended |\n",
    "| 5 | Belief Propagation | 0% | Fast (0.01s) | Needs tuning |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Graph Cuts achieves globally optimal solution** - Uses min-cut/max-flow to solve exactly\n",
    "\n",
    "2. **Hierarchical provides 87% recovery** - Q-tensor averaging at coarse scales captures global structure\n",
    "\n",
    "3. **Simulated Annealing is too slow** - Even with 50k iterations, doesn't match deterministic methods\n",
    "\n",
    "4. **All methods achieve similar angular error on noisy data** - Sign optimization primarily affects energy, not direction accuracy\n",
    "\n",
    "### Recommended Workflow\n",
    "\n",
    "```python\n",
    "from v2.approaches import GraphCutsOptimizer\n",
    "\n",
    "# Default: Use Graph Cuts\n",
    "optimizer = GraphCutsOptimizer()\n",
    "result = optimizer.optimize(director_raw, verbose=True)\n",
    "optimized = result.director\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:15:00.082304Z",
     "start_time": "2026-02-03T06:15:00.079901Z"
    }
   },
   "source": [
    "# Final summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY: SCRAMBLED SIGNS TEST\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Method':<25} {'Recovery':>12} {'Time':>12} {'Verdict':>15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "verdicts = {\n",
    "    'Graph Cuts': 'BEST',\n",
    "    'Hierarchical': 'Good',\n",
    "    'V2 Layer+Refine': 'Baseline',\n",
    "    'Simulated Annealing': 'Slow',\n",
    "    'Belief Propagation': 'Failed'\n",
    "}\n",
    "\n",
    "for name in scrambled_results:\n",
    "    r = scrambled_results[name]\n",
    "    print(f\"{name:<25} {r['recovery']:>11.1f}% {r['time']:>11.2f}s {verdicts[name]:>15}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRecommendation: Use Graph Cuts (PyMaxflow) for optimal results.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY: SCRAMBLED SIGNS TEST\n",
      "======================================================================\n",
      "\n",
      "Method                        Recovery         Time         Verdict\n",
      "----------------------------------------------------------------------\n",
      "V2 Layer+Refine                  46.7%        0.05s        Baseline\n",
      "Graph Cuts                      100.0%        0.04s            BEST\n",
      "Hierarchical                     87.0%        0.04s            Good\n",
      "Simulated Annealing              61.5%       24.77s            Slow\n",
      "Belief Propagation                0.0%        0.01s          Failed\n",
      "======================================================================\n",
      "\n",
      "Recommendation: Use Graph Cuts (PyMaxflow) for optimal results.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T06:15:00.087601Z",
     "start_time": "2026-02-03T06:15:00.086102Z"
    }
   },
   "source": [
    "print(\"\\nPresentation notebook complete!\")\n",
    "print(\"\\nGenerated figures:\")\n",
    "print(\"  • scrambled_test_results.png\")\n",
    "print(\"  • director_slices_comparison.png\")\n",
    "print(\"  • noise_sensitivity.png\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Presentation notebook complete!\n",
      "\n",
      "Generated figures:\n",
      "  • scrambled_test_results.png\n",
      "  • director_slices_comparison.png\n",
      "  • noise_sensitivity.png\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
