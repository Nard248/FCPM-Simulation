{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soliton Validation: Sign Optimization Benchmark\n",
    "\n",
    "This notebook validates all sign-optimization approaches on liquid crystal director fields.\n",
    "It provides a controlled benchmark by:\n",
    "\n",
    "1. Loading a director field (real LCSim data or synthetic cholesteric)\n",
    "2. Randomly scrambling 50% of voxel signs (known ground truth)\n",
    "3. Running all 6 sign-optimization methods\n",
    "4. Comparing: energy recovery, sign accuracy, timing\n",
    "5. Visualizing results: director slices, error maps, Frank energy decomposition\n",
    "\n",
    "**Optimizers tested:**\n",
    "- Combined (V1 chain propagation + iterative flip)\n",
    "- Layer Propagation (layer-by-layer + refinement)\n",
    "- Graph Cuts (min-cut/max-flow on neighborhood graph)\n",
    "- Simulated Annealing (Metropolis-Hastings with adaptive temperature)\n",
    "- Hierarchical (multi-scale coarse-to-fine)\n",
    "- Belief Propagation (message passing on factor graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import fcpm\n",
    "from fcpm.reconstruction.base import OptimizationResult\n",
    "from fcpm.reconstruction.optimizers import (\n",
    "    CombinedOptimizer,\n",
    "    LayerPropagationOptimizer,\n",
    "    GraphCutsOptimizer,\n",
    "    SimulatedAnnealingOptimizer,\n",
    "    SimulatedAnnealingConfig,\n",
    "    HierarchicalOptimizer,\n",
    "    BeliefPropagationOptimizer,\n",
    "    BeliefPropagationConfig,\n",
    ")\n",
    "\n",
    "print(f\"FCPM version: {fcpm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Director Field\n",
    "\n",
    "If you have real LCSim data (e.g. cholesteric fingers, Z-solitons, torons from article.lcpen),\n",
    "set `DATA_PATH` below. Otherwise, a synthetic cholesteric is used as fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to your LCSim NPZ file path, or None for synthetic\n",
    "DATA_PATH = None  # e.g. '../data/CF1.npz'\n",
    "SEED = 42\n",
    "\n",
    "if DATA_PATH is not None:\n",
    "    from pathlib import Path\n",
    "    if Path(DATA_PATH).exists():\n",
    "        director_gt, settings = fcpm.load_lcsim_npz(DATA_PATH)\n",
    "        print(f\"Loaded LCSim data from {DATA_PATH}\")\n",
    "        print(f\"Shape: {director_gt.shape}\")\n",
    "        if settings:\n",
    "            print(f\"Settings: {settings}\")\n",
    "    else:\n",
    "        print(f\"File not found: {DATA_PATH}, using synthetic fallback\")\n",
    "        DATA_PATH = None\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    director_gt = fcpm.create_cholesteric_director(shape=(64, 64, 32), pitch=8.0)\n",
    "    print(f\"Created synthetic cholesteric: shape={director_gt.shape}, pitch=8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ground truth\n",
    "z_mid = director_gt.shape[2] // 2\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "fcpm.plot_director_slice(director_gt, z_idx=0, step=2, ax=axes[0],\n",
    "                         title=f'Ground Truth (z=0)')\n",
    "fcpm.plot_director_slice(director_gt, z_idx=z_mid, step=2, ax=axes[1],\n",
    "                         title=f'Ground Truth (z={z_mid})')\n",
    "fcpm.plot_director_slice(director_gt, z_idx=director_gt.shape[2]-1, step=2, ax=axes[2],\n",
    "                         title=f'Ground Truth (z={director_gt.shape[2]-1})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scramble Signs (Controlled Test)\n",
    "\n",
    "Randomly flip the sign of 50% of voxels. Since we know the ground truth,\n",
    "we can measure both energy recovery and sign accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_signs(director, seed=42):\n",
    "    \"\"\"Randomly flip signs of 50% of voxels.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = director.to_array().copy()\n",
    "    mask = rng.random(n.shape[:3]) < 0.5\n",
    "    n[mask] = -n[mask]\n",
    "    return fcpm.DirectorField.from_array(n, metadata=director.metadata)\n",
    "\n",
    "director_scrambled = scramble_signs(director_gt, seed=SEED)\n",
    "\n",
    "gt_energy = fcpm.compute_gradient_energy(director_gt)\n",
    "scrambled_energy = fcpm.compute_gradient_energy(director_scrambled)\n",
    "\n",
    "print(f\"Ground truth energy:  {gt_energy:.2f}\")\n",
    "print(f\"Scrambled energy:     {scrambled_energy:.2f}\")\n",
    "print(f\"Energy increase:      {scrambled_energy - gt_energy:.2f} \"\n",
    "      f\"({100*(scrambled_energy - gt_energy)/gt_energy:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scrambled vs ground truth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fcpm.plot_director_slice(director_gt, z_idx=z_mid, step=2, ax=axes[0],\n",
    "                         title='Ground Truth')\n",
    "fcpm.plot_director_slice(director_scrambled, z_idx=z_mid, step=2, ax=axes[1],\n",
    "                         title='Scrambled (50% flipped)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run All Optimizers\n",
    "\n",
    "Each optimizer receives the same scrambled director field and attempts to recover\n",
    "consistent signs. We track energy reduction, sign accuracy, and wall-clock time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    (\"Combined (V1)\", CombinedOptimizer()),\n",
    "    (\"LayerPropagation\", LayerPropagationOptimizer()),\n",
    "    (\"GraphCuts\", GraphCutsOptimizer()),\n",
    "    (\"SimulatedAnnealing\", SimulatedAnnealingOptimizer(\n",
    "        SimulatedAnnealingConfig(max_iterations=10000, seed=SEED))),\n",
    "    (\"Hierarchical\", HierarchicalOptimizer()),\n",
    "    (\"BeliefPropagation\", BeliefPropagationOptimizer(\n",
    "        BeliefPropagationConfig(max_iterations=30))),\n",
    "]\n",
    "\n",
    "results = []\n",
    "result_directors = {}  # Store optimized directors for visualization\n",
    "\n",
    "for name, optimizer in optimizers:\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    t0 = time.perf_counter()\n",
    "    result: OptimizationResult = optimizer.optimize(director_scrambled, verbose=True)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    sign_acc = fcpm.sign_accuracy(result.director, director_gt)\n",
    "\n",
    "    energy_gap = scrambled_energy - gt_energy\n",
    "    recovered = scrambled_energy - result.final_energy\n",
    "    recovery_pct = 100.0 * recovered / energy_gap if energy_gap > 0 else 100.0\n",
    "\n",
    "    metrics = {\n",
    "        \"method\": name,\n",
    "        \"initial_energy\": result.initial_energy,\n",
    "        \"final_energy\": result.final_energy,\n",
    "        \"energy_reduction_pct\": result.energy_reduction_pct,\n",
    "        \"sign_accuracy\": sign_acc,\n",
    "        \"energy_recovery_pct\": round(recovery_pct, 2),\n",
    "        \"total_flips\": result.total_flips,\n",
    "        \"time_s\": round(elapsed, 3),\n",
    "    }\n",
    "    results.append(metrics)\n",
    "    result_directors[name] = result.director\n",
    "\n",
    "    print(f\"  Energy: {metrics['initial_energy']:.1f} -> {metrics['final_energy']:.1f} \"\n",
    "          f\"({metrics['energy_reduction_pct']:.1f}% reduction)\")\n",
    "    print(f\"  Sign accuracy: {sign_acc:.3f}\")\n",
    "    print(f\"  Energy recovery: {recovery_pct:.1f}%\")\n",
    "    print(f\"  Time: {elapsed:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Method':<25} {'Energy Red%':>10} {'Sign Acc':>10} {'E Recovery%':>12} {'Time(s)':>8}\")\n",
    "print(\"-\" * 70)\n",
    "for r in results:\n",
    "    print(f\"{r['method']:<25} {r['energy_reduction_pct']:>9.1f}% \"\n",
    "          f\"{r['sign_accuracy']:>9.3f} \"\n",
    "          f\"{r['energy_recovery_pct']:>11.1f}% \"\n",
    "          f\"{r['time_s']:>7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method Comparison (Bar Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [r['method'] for r in results]\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Energy reduction\n",
    "axes[0].bar(x, [r['energy_reduction_pct'] for r in results], color='steelblue')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods, rotation=45, ha='right', fontsize=8)\n",
    "axes[0].set_ylabel('Energy Reduction (%)')\n",
    "axes[0].set_title('Energy Reduction')\n",
    "\n",
    "# Sign accuracy\n",
    "axes[1].bar(x, [r['sign_accuracy'] for r in results], color='forestgreen')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(methods, rotation=45, ha='right', fontsize=8)\n",
    "axes[1].set_ylabel('Sign Accuracy')\n",
    "axes[1].set_title('Sign Accuracy')\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "\n",
    "# Timing\n",
    "axes[2].bar(x, [r['time_s'] for r in results], color='coral')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(methods, rotation=45, ha='right', fontsize=8)\n",
    "axes[2].set_ylabel('Time (s)')\n",
    "axes[2].set_title('Execution Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Director Slice Comparison\n",
    "\n",
    "Visual comparison of each optimizer's output against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_methods = len(result_directors)\n",
    "fig, axes = plt.subplots(2, (n_methods + 2) // 2, figsize=(5 * ((n_methods + 2) // 2), 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Ground truth and scrambled\n",
    "fcpm.plot_director_slice(director_gt, z_idx=z_mid, step=2, ax=axes[0],\n",
    "                         title='Ground Truth')\n",
    "fcpm.plot_director_slice(director_scrambled, z_idx=z_mid, step=2, ax=axes[1],\n",
    "                         title='Scrambled')\n",
    "\n",
    "# Each optimizer result\n",
    "for i, (name, d) in enumerate(result_directors.items()):\n",
    "    r = results[i]\n",
    "    fcpm.plot_director_slice(d, z_idx=z_mid, step=2, ax=axes[i + 2],\n",
    "                             title=f\"{name}\\nacc={r['sign_accuracy']:.3f}\")\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(n_methods + 2, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Maps\n",
    "\n",
    "Per-voxel angular error relative to the ground truth for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, d) in enumerate(result_directors.items()):\n",
    "    fcpm.plot_error_map(d, director_gt, z_idx=z_mid, ax=axes[i])\n",
    "    axes[i].set_title(f\"{name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Frank Energy Decomposition (Splay/Twist/Bend)\n",
    "\n",
    "Decompose the elastic energy into splay, twist, and bend contributions\n",
    "for the ground truth and the best optimizer result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcpm.reconstruction.energy import FrankConstants, compute_frank_energy_anisotropic\n",
    "\n",
    "# Use article.lcpen constants for 5CB\n",
    "frank = FrankConstants(K1=10.3, K2=7.4, K3=16.48)\n",
    "\n",
    "# Ground truth energy decomposition\n",
    "gt_frank = compute_frank_energy_anisotropic(director_gt.to_array(), frank)\n",
    "print(\"Ground Truth Frank Energy:\")\n",
    "print(f\"  Splay:  {gt_frank['splay_integrated']:.2f}\")\n",
    "print(f\"  Twist:  {gt_frank['twist_integrated']:.2f}\")\n",
    "print(f\"  Bend:   {gt_frank['bend_integrated']:.2f}\")\n",
    "print(f\"  Total:  {gt_frank['total_integrated']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best method by sign accuracy\n",
    "best_idx = max(range(len(results)), key=lambda i: results[i]['sign_accuracy'])\n",
    "best_name = results[best_idx]['method']\n",
    "best_director = result_directors[best_name]\n",
    "\n",
    "best_frank = compute_frank_energy_anisotropic(best_director.to_array(), frank)\n",
    "print(f\"Best Method: {best_name}\")\n",
    "print(f\"  Splay:  {best_frank['splay_integrated']:.2f}\")\n",
    "print(f\"  Twist:  {best_frank['twist_integrated']:.2f}\")\n",
    "print(f\"  Bend:   {best_frank['bend_integrated']:.2f}\")\n",
    "print(f\"  Total:  {best_frank['total_integrated']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparing Frank energy components\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "components = ['Splay', 'Twist', 'Bend']\n",
    "gt_vals = [gt_frank['splay_integrated'], gt_frank['twist_integrated'],\n",
    "           gt_frank['bend_integrated']]\n",
    "best_vals = [best_frank['splay_integrated'], best_frank['twist_integrated'],\n",
    "             best_frank['bend_integrated']]\n",
    "\n",
    "x = np.arange(len(components))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, gt_vals, width, label='Ground Truth', color='steelblue')\n",
    "ax.bar(x + width/2, best_vals, width, label=f'{best_name}', color='coral')\n",
    "\n",
    "ax.set_xlabel('Energy Component')\n",
    "ax.set_ylabel('Integrated Energy')\n",
    "ax.set_title('Frank Energy Decomposition')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(components)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Noise Sensitivity on Soliton Structures\n",
    "\n",
    "Test how each optimizer handles sign recovery after noise has been added to the\n",
    "FCPM simulation-reconstruction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0.01, 0.03, 0.05, 0.10]\n",
    "noise_results = {name: [] for name, _ in optimizers}\n",
    "\n",
    "# Simulate clean FCPM\n",
    "I_clean = fcpm.simulate_fcpm(director_gt)\n",
    "\n",
    "for noise_sigma in noise_levels:\n",
    "    print(f\"\\nNoise level: {noise_sigma*100:.0f}%\")\n",
    "\n",
    "    # Add noise and reconstruct (introduces real sign errors)\n",
    "    I_noisy = fcpm.add_fcpm_realistic_noise(\n",
    "        I_clean, noise_model='gaussian', gaussian_sigma=noise_sigma, seed=SEED)\n",
    "    I_noisy = fcpm.normalize_fcpm(I_noisy)\n",
    "    director_recon, _ = fcpm.reconstruct(I_noisy, fix_signs=False, verbose=False)\n",
    "\n",
    "    for name, optimizer in optimizers:\n",
    "        result = optimizer.optimize(director_recon, verbose=False)\n",
    "        acc = fcpm.sign_accuracy(result.director, director_gt)\n",
    "        noise_results[name].append(acc)\n",
    "        print(f\"  {name:<25} sign_accuracy={acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot noise sensitivity\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "noise_pct = [n * 100 for n in noise_levels]\n",
    "\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(optimizers)))\n",
    "for i, (name, _) in enumerate(optimizers):\n",
    "    ax.plot(noise_pct, noise_results[name], 'o-', label=name,\n",
    "            color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('Noise Level (%)', fontsize=12)\n",
    "ax.set_ylabel('Sign Accuracy', fontsize=12)\n",
    "ax.set_title('Sign Recovery vs Noise Level', fontsize=14)\n",
    "ax.set_ylim(0.4, 1.05)\n",
    "ax.legend(fontsize=9, loc='lower left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Spatial Error Distribution (Per-Layer Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-layer error for the best method\n",
    "dist = fcpm.spatial_error_distribution(best_director, director_gt)\n",
    "\n",
    "z_layers = np.arange(len(dist['layer_mean']))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.fill_between(z_layers, 0, dist['layer_max'], alpha=0.2, color='red', label='Max')\n",
    "ax.fill_between(z_layers, 0, dist['layer_mean'], alpha=0.3, color='steelblue', label='Mean')\n",
    "ax.plot(z_layers, dist['layer_median'], 'g-', linewidth=2, label='Median')\n",
    "\n",
    "ax.set_xlabel('Z Layer', fontsize=12)\n",
    "ax.set_ylabel('Angular Error (degrees)', fontsize=12)\n",
    "ax.set_title(f'Error Distribution by Depth ({best_name})', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key observations:\n",
    "- **Graph Cuts** typically achieves the highest sign accuracy on clean data (global optimum for binary labeling)\n",
    "- **Hierarchical** provides a good balance of speed and accuracy\n",
    "- **Combined (V1)** remains a reliable baseline\n",
    "- **Simulated Annealing** can achieve excellent results but requires more time\n",
    "- **Belief Propagation** is experimental and may not converge on all structures\n",
    "\n",
    "For real-world use, we recommend starting with **Graph Cuts** or **Hierarchical** for most applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
